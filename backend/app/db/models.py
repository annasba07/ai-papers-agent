"""
SQLAlchemy models for knowledge graph

Uses pgvector for vector embeddings stored in Supabase PostgreSQL.
"""
from sqlalchemy import (
    Column, String, Text, Integer, Float, Boolean, DateTime,
    ForeignKey, UniqueConstraint, CheckConstraint, Index, ARRAY
)
from sqlalchemy.dialects.postgresql import JSONB, TSVECTOR
from sqlalchemy.sql import func
from datetime import datetime

try:
    from pgvector.sqlalchemy import Vector
except ImportError:
    # Fallback if pgvector not installed
    from sqlalchemy import Text as Vector

from app.db.database import Base


class Paper(Base):
    """
    Core paper metadata with vector embeddings for semantic search
    """
    __tablename__ = "papers"

    # Identity
    id = Column(String(50), primary_key=True, comment="arXiv ID")

    # Basic metadata
    title = Column(Text, nullable=False, index=True)
    abstract = Column(Text, nullable=False)
    authors = Column(JSONB, nullable=False, default=list)
    published_date = Column(DateTime, nullable=False, index=True)
    updated_date = Column(DateTime, nullable=True)
    category = Column(String(20), nullable=False, index=True)

    # Vector embedding for semantic similarity
    embedding = Column(Vector(1536), nullable=True, comment="OpenAI ada-002 embedding")

    # Computed metrics (denormalized for speed)
    citation_count = Column(Integer, default=0, index=True)
    influential_citation_count = Column(Integer, default=0)
    quality_score = Column(Float, default=0.0, index=True)

    # Rich cached data
    ai_analysis = Column(JSONB, nullable=True)
    code_repos = Column(JSONB, nullable=True)
    concepts_array = Column(ARRAY(Text), default=list)

    # Full-text search (auto-generated by trigger)
    search_vector = Column(TSVECTOR, nullable=True)

    # Housekeeping
    ingested_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Indexes defined at table level
    __table_args__ = (
        Index('papers_category_published_idx', 'category', 'published_date'),
        Index('papers_quality_published_idx', 'quality_score', 'published_date'),
        Index('papers_search_vector_idx', 'search_vector', postgresql_using='gin'),
        Index('papers_concepts_array_idx', 'concepts_array', postgresql_using='gin'),
    )


class Technique(Base):
    """
    Canonical technique/model/architecture entity referenced by papers
    """
    __tablename__ = "techniques"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    normalized_name = Column(String(200), nullable=False, index=True)
    method_type = Column(String(100), nullable=True, index=True)
    emergence_date = Column(DateTime, nullable=True)
    maturity_score = Column(Float, default=0.0)
    description = Column(Text, nullable=True)
    embedding = Column(Vector(1536), nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    __table_args__ = (
        Index('techniques_type_maturity_idx', 'method_type', 'maturity_score'),
    )


class Task(Base):
    """
    Downstream problems or objectives addressed by papers/techniques
    """
    __tablename__ = "tasks"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    taxonomy_path = Column(String(400), nullable=True)
    modality = Column(String(100), nullable=True, index=True)
    application_domain = Column(String(150), nullable=True, index=True)
    description = Column(Text, nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    __table_args__ = (
        Index('tasks_taxonomy_idx', 'taxonomy_path'),
    )


class Dataset(Base):
    """
    Datasets used for training/evaluation
    """
    __tablename__ = "datasets"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    normalized_name = Column(String(200), nullable=False, index=True)
    modality = Column(String(100), nullable=True, index=True)
    sample_count = Column(Integer, nullable=True)
    license = Column(String(100), nullable=True)
    maintainer = Column(String(200), nullable=True)
    url = Column(String(300), nullable=True)
    embedding = Column(Vector(1536), nullable=True)
    extra_metadata = Column(JSONB, nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    __table_args__ = (
        Index('datasets_modality_idx', 'modality'),
    )


class Organisation(Base):
    """
    Institutions, labs, and companies associated with authors/papers
    """
    __tablename__ = "organisations"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    kind = Column(String(50), nullable=True, index=True)  # academic, industry, open_source
    region = Column(String(100), nullable=True, index=True)
    homepage = Column(String(300), nullable=True)
    research_focus = Column(JSONB, nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    __table_args__ = (
        Index('organisations_kind_region_idx', 'kind', 'region'),
    )


class Author(Base):
    """
    Individual researchers with optional ORCID and affiliation data
    """
    __tablename__ = "authors"

    id = Column(Integer, primary_key=True)
    full_name = Column(String(200), nullable=False)
    normalized_name = Column(String(200), nullable=False, index=True)
    orcid = Column(String(50), nullable=True, unique=True)
    homepage = Column(String(300), nullable=True)
    primary_affiliation_id = Column(
        Integer,
        ForeignKey('organisations.id', ondelete='SET NULL'),
        nullable=True
    )
    stats = Column(JSONB, nullable=True)  # Aggregate metrics (citations, h-index, etc.)

    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    __table_args__ = (
        Index('authors_affiliation_idx', 'primary_affiliation_id'),
        UniqueConstraint('full_name', 'primary_affiliation_id', name='uq_authors_name_affiliation'),
    )


class Concept(Base):
    """
    Research concepts/topics/techniques extracted from papers
    """
    __tablename__ = "concepts"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    normalized_name = Column(String(200), nullable=False, index=True)
    category = Column(
        String(50),
        nullable=True,
        comment="architecture, technique, dataset, task, etc."
    )

    # Metadata
    paper_count = Column(Integer, default=0, index=True)
    first_seen_date = Column(DateTime, default=datetime.utcnow)
    last_seen_date = Column(DateTime, default=datetime.utcnow)

    # Optional: embeddings for concept similarity
    embedding = Column(Vector(1536), nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        Index('concepts_category_count_idx', 'category', 'paper_count'),
    )


class PaperConcept(Base):
    """
    Many-to-many relationship between papers and concepts with relevance scores
    """
    __tablename__ = "paper_concepts"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    concept_id = Column(
        Integer,
        ForeignKey('concepts.id', ondelete='CASCADE'),
        primary_key=True
    )
    relevance = Column(
        Float,
        nullable=False,
        comment="0.0 to 1.0"
    )

    # Metadata
    extraction_method = Column(String(50), nullable=True)
    confidence = Column(Float, default=1.0)

    __table_args__ = (
        CheckConstraint('relevance >= 0 AND relevance <= 1', name='check_relevance_range'),
        Index('paper_concepts_concept_relevance_idx', 'concept_id', 'relevance'),
        Index('paper_concepts_paper_idx', 'paper_id'),
    )


class Citation(Base):
    """
    Directed graph of paper citations
    """
    __tablename__ = "citations"

    citing_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    cited_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )

    # Citation metadata
    is_influential = Column(Boolean, default=False, index=True)
    context_snippet = Column(Text, nullable=True)
    section = Column(String(50), nullable=True)

    # Computed for temporal analysis
    citation_year = Column(Integer, nullable=True, index=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        Index('citations_citing_idx', 'citing_paper_id'),
        Index('citations_cited_idx', 'cited_paper_id'),
        Index('citations_year_idx', 'citation_year'),
    )


class Benchmark(Base):
    """
    Performance metrics of papers on standard datasets
    """
    __tablename__ = "benchmarks"

    id = Column(Integer, primary_key=True)
    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        nullable=False,
        index=True
    )

    # What was tested (structured + legacy strings)
    task_id = Column(
        Integer,
        ForeignKey('tasks.id', ondelete='SET NULL'),
        nullable=True,
        index=True
    )
    dataset_id = Column(
        Integer,
        ForeignKey('datasets.id', ondelete='SET NULL'),
        nullable=True,
        index=True
    )
    task = Column(String(100), nullable=False, index=True)
    dataset = Column(String(100), nullable=False, index=True)
    metric = Column(String(50), nullable=False, index=True)

    # Performance
    value = Column(Float, nullable=False)

    # Additional context
    model_name = Column(String(200), nullable=True)
    model_size = Column(String(50), nullable=True)
    compute_cost = Column(String(100), nullable=True)

    # Metadata
    reported_date = Column(DateTime, nullable=True)
    extra_metadata = Column(JSONB, nullable=True)
    evidence_source = Column(String(50), nullable=True)  # llm, table_extraction, pwc

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        UniqueConstraint(
            'paper_id', 'task', 'dataset', 'metric', 'model_name',
            name='unique_benchmark'
        ),
        UniqueConstraint(
            'paper_id', 'task_id', 'dataset_id', 'metric', 'model_name',
            name='unique_benchmark_fk'
        ),
        Index('benchmarks_task_dataset_value_idx', 'task', 'dataset', 'value'),
        Index('benchmarks_task_dataset_date_idx', 'task', 'dataset', 'reported_date'),
        Index('benchmarks_task_id_dataset_id_idx', 'task_id', 'dataset_id'),
    )


class PaperTechnique(Base):
    """
    Mapping between papers and techniques with roles (e.g., core, baseline)
    """
    __tablename__ = "paper_techniques"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    technique_id = Column(
        Integer,
        ForeignKey('techniques.id', ondelete='CASCADE'),
        primary_key=True
    )
    role = Column(String(50), nullable=True)  # core, baseline, ablation, comparison
    confidence = Column(Float, default=1.0)
    evidence_source = Column(String(50), nullable=True)
    notes = Column(Text, nullable=True)

    __table_args__ = (
        CheckConstraint('confidence >= 0 AND confidence <= 1', name='check_paper_technique_confidence'),
        Index('paper_techniques_technique_role_idx', 'technique_id', 'role'),
        Index('paper_techniques_paper_idx', 'paper_id'),
    )


class PaperTask(Base):
    """
    Mapping between papers and the tasks/problems they address
    """
    __tablename__ = "paper_tasks"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    task_id = Column(
        Integer,
        ForeignKey('tasks.id', ondelete='CASCADE'),
        primary_key=True
    )
    evidence_source = Column(String(50), nullable=True)
    notes = Column(Text, nullable=True)

    __table_args__ = (
        Index('paper_tasks_task_idx', 'task_id'),
        Index('paper_tasks_paper_idx', 'paper_id'),
    )


class PaperDataset(Base):
    """
    Mapping between papers and datasets they use
    """
    __tablename__ = "paper_datasets"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    dataset_id = Column(
        Integer,
        ForeignKey('datasets.id', ondelete='CASCADE'),
        primary_key=True
    )
    usage_type = Column(String(50), nullable=True)  # train / eval / pretrain
    notes = Column(Text, nullable=True)

    __table_args__ = (
        Index('paper_datasets_dataset_idx', 'dataset_id', 'usage_type'),
        Index('paper_datasets_paper_idx', 'paper_id'),
    )


class PaperAuthor(Base):
    """
    Authorship ordering and roles for papers
    """
    __tablename__ = "paper_authors"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    author_id = Column(
        Integer,
        ForeignKey('authors.id', ondelete='CASCADE'),
        primary_key=True
    )
    author_order = Column(Integer, nullable=True)
    is_corresponding = Column(Boolean, default=False)

    __table_args__ = (
        Index('paper_authors_author_idx', 'author_id'),
        Index('paper_authors_order_idx', 'paper_id', 'author_order'),
    )


class AuthorOrganisation(Base):
    """
    Historical affiliations for authors
    """
    __tablename__ = "author_organisations"

    id = Column(Integer, primary_key=True)
    author_id = Column(
        Integer,
        ForeignKey('authors.id', ondelete='CASCADE'),
        nullable=False
    )
    organisation_id = Column(
        Integer,
        ForeignKey('organisations.id', ondelete='CASCADE'),
        nullable=False
    )
    start_date = Column(DateTime, nullable=True)
    end_date = Column(DateTime, nullable=True)
    role = Column(String(100), nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        UniqueConstraint(
            'author_id', 'organisation_id', 'start_date', 'end_date',
            name='uq_author_org_tenure'
        ),
        Index('author_organisations_author_idx', 'author_id'),
        Index('author_organisations_org_idx', 'organisation_id'),
    )


class TechniqueRelationship(Base):
    """
    Relationships between techniques (extends, alternative_to, compatible_with, etc.)
    """
    __tablename__ = "technique_relationships"

    technique_a_id = Column(
        Integer,
        ForeignKey('techniques.id', ondelete='CASCADE'),
        primary_key=True
    )
    technique_b_id = Column(
        Integer,
        ForeignKey('techniques.id', ondelete='CASCADE'),
        primary_key=True
    )
    relation_type = Column(String(50), nullable=False)
    weight = Column(Float, nullable=True)
    first_seen_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='SET NULL'),
        nullable=True
    )
    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        CheckConstraint('technique_a_id < technique_b_id', name='check_technique_relationship_order'),
        Index('technique_relationships_type_idx', 'relation_type'),
    )


class TechniqueBenchmark(Base):
    """
    Associative table connecting techniques to benchmark results
    """
    __tablename__ = "technique_benchmarks"

    technique_id = Column(
        Integer,
        ForeignKey('techniques.id', ondelete='CASCADE'),
        primary_key=True
    )
    benchmark_id = Column(
        Integer,
        ForeignKey('benchmarks.id', ondelete='CASCADE'),
        primary_key=True
    )
    delta_from_sota = Column(Float, nullable=True)
    sota_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='SET NULL'),
        nullable=True
    )
    notes = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        Index('technique_benchmarks_delta_idx', 'delta_from_sota'),
    )


class PaperRelationship(Base):
    """
    Pre-computed paper relationships for faster queries
    (Materialized similarity scores)
    """
    __tablename__ = "paper_relationships"

    paper_a_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    paper_b_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )

    # Different types of similarity
    semantic_similarity = Column(Float, nullable=True)
    concept_similarity = Column(Float, nullable=True)
    citation_distance = Column(Integer, nullable=True)

    computed_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        CheckConstraint('paper_a_id < paper_b_id', name='check_paper_order'),
    )
