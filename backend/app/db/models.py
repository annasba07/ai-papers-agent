"""
SQLAlchemy models for knowledge graph

Uses pgvector for vector embeddings stored in Supabase PostgreSQL.
"""
from sqlalchemy import (
    Column, String, Text, Integer, Float, Boolean, DateTime,
    ForeignKey, UniqueConstraint, CheckConstraint, Index, ARRAY
)
from sqlalchemy.dialects.postgresql import JSONB, TSVECTOR
from sqlalchemy.sql import func
from datetime import datetime

try:
    from pgvector.sqlalchemy import Vector
except ImportError:
    # Fallback if pgvector not installed
    from sqlalchemy import Text as Vector

from app.db.database import Base


class Paper(Base):
    """
    Core paper metadata with vector embeddings for semantic search
    """
    __tablename__ = "papers"

    # Identity
    id = Column(String(50), primary_key=True, comment="arXiv ID")

    # Basic metadata
    title = Column(Text, nullable=False, index=True)
    abstract = Column(Text, nullable=False)
    authors = Column(JSONB, nullable=False, default=list)
    published_date = Column(DateTime, nullable=False, index=True)
    updated_date = Column(DateTime, nullable=True)
    category = Column(String(20), nullable=False, index=True)

    # Vector embedding for semantic similarity
    embedding = Column(Vector(1536), nullable=True, comment="OpenAI ada-002 embedding")

    # Computed metrics (denormalized for speed)
    citation_count = Column(Integer, default=0, index=True)
    influential_citation_count = Column(Integer, default=0)
    quality_score = Column(Float, default=0.0, index=True)

    # Rich cached data
    ai_analysis = Column(JSONB, nullable=True)
    code_repos = Column(JSONB, nullable=True)
    concepts_array = Column(ARRAY(Text), default=list)

    # Full-text search (auto-generated by trigger)
    search_vector = Column(TSVECTOR, nullable=True)

    # Housekeeping
    ingested_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Indexes defined at table level
    __table_args__ = (
        Index('papers_category_published_idx', 'category', 'published_date'),
        Index('papers_quality_published_idx', 'quality_score', 'published_date'),
        Index('papers_search_vector_idx', 'search_vector', postgresql_using='gin'),
        Index('papers_concepts_array_idx', 'concepts_array', postgresql_using='gin'),
    )


class Concept(Base):
    """
    Research concepts/topics/techniques extracted from papers
    """
    __tablename__ = "concepts"

    id = Column(Integer, primary_key=True)
    name = Column(String(200), unique=True, nullable=False)
    normalized_name = Column(String(200), nullable=False, index=True)
    category = Column(
        String(50),
        nullable=True,
        comment="architecture, technique, dataset, task, etc."
    )

    # Metadata
    paper_count = Column(Integer, default=0, index=True)
    first_seen_date = Column(DateTime, default=datetime.utcnow)
    last_seen_date = Column(DateTime, default=datetime.utcnow)

    # Optional: embeddings for concept similarity
    embedding = Column(Vector(1536), nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        Index('concepts_category_count_idx', 'category', 'paper_count'),
    )


class PaperConcept(Base):
    """
    Many-to-many relationship between papers and concepts with relevance scores
    """
    __tablename__ = "paper_concepts"

    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    concept_id = Column(
        Integer,
        ForeignKey('concepts.id', ondelete='CASCADE'),
        primary_key=True
    )
    relevance = Column(
        Float,
        nullable=False,
        comment="0.0 to 1.0"
    )

    # Metadata
    extraction_method = Column(String(50), nullable=True)
    confidence = Column(Float, default=1.0)

    __table_args__ = (
        CheckConstraint('relevance >= 0 AND relevance <= 1', name='check_relevance_range'),
        Index('paper_concepts_concept_relevance_idx', 'concept_id', 'relevance'),
        Index('paper_concepts_paper_idx', 'paper_id'),
    )


class Citation(Base):
    """
    Directed graph of paper citations
    """
    __tablename__ = "citations"

    citing_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    cited_paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )

    # Citation metadata
    is_influential = Column(Boolean, default=False, index=True)
    context_snippet = Column(Text, nullable=True)
    section = Column(String(50), nullable=True)

    # Computed for temporal analysis
    citation_year = Column(Integer, nullable=True, index=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        Index('citations_citing_idx', 'citing_paper_id'),
        Index('citations_cited_idx', 'cited_paper_id'),
        Index('citations_year_idx', 'citation_year'),
    )


class Benchmark(Base):
    """
    Performance metrics of papers on standard datasets
    """
    __tablename__ = "benchmarks"

    id = Column(Integer, primary_key=True)
    paper_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        nullable=False,
        index=True
    )

    # What was tested
    task = Column(String(100), nullable=False, index=True)
    dataset = Column(String(100), nullable=False, index=True)
    metric = Column(String(50), nullable=False)

    # Performance
    value = Column(Float, nullable=False)

    # Additional context
    model_name = Column(String(200), nullable=True)
    model_size = Column(String(50), nullable=True)
    compute_cost = Column(String(100), nullable=True)

    # Metadata
    reported_date = Column(DateTime, nullable=True)
    metadata = Column(JSONB, nullable=True)

    created_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        UniqueConstraint(
            'paper_id', 'task', 'dataset', 'metric', 'model_name',
            name='unique_benchmark'
        ),
        Index('benchmarks_task_dataset_value_idx', 'task', 'dataset', 'value'),
        Index('benchmarks_task_dataset_date_idx', 'task', 'dataset', 'reported_date'),
    )


class PaperRelationship(Base):
    """
    Pre-computed paper relationships for faster queries
    (Materialized similarity scores)
    """
    __tablename__ = "paper_relationships"

    paper_a_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )
    paper_b_id = Column(
        String(50),
        ForeignKey('papers.id', ondelete='CASCADE'),
        primary_key=True
    )

    # Different types of similarity
    semantic_similarity = Column(Float, nullable=True)
    concept_similarity = Column(Float, nullable=True)
    citation_distance = Column(Integer, nullable=True)

    computed_at = Column(DateTime, default=datetime.utcnow)

    __table_args__ = (
        CheckConstraint('paper_a_id < paper_b_id', name='check_paper_order'),
    )
