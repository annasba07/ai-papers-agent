# UX Assessment Report: Dr. Emily Zhang
## Interdisciplinary Climate Researcher

**Date**: 2025-12-25
**Session Duration**: ~20 minutes
**Persona**: Dr. Emily Zhang - Climate scientist applying ML to weather prediction
**Scenario**: Exploring transformers for climate time series forecasting

---

## Executive Summary

As an atmospheric scientist teaching myself ML, I found **AI Paper Atlas bridges the ML-climate vocabulary gap surprisingly well**. The Research Advisor understood my cross-domain query and surfaced climate-specific papers I wouldn't have found through keyword search alone. However, the tool still assumes significant ML fluency - terminology like "transformers," "attention mechanisms," and "embeddings" appeared without explanation, which would challenge domain scientists new to ML.

**Verdict**: Would bookmark and recommend to climate science colleagues, with caveats about the ML learning curve. **4/5**

---

## Session Timeline

| Time | Action | Outcome | Emotion (1-5) |
|------|--------|---------|---------------|
| 0:00 | Loaded explore page | Initial loading took ~3-5s, saw skeleton screens | 3/5 Neutral |
| 0:08 | Page fully rendered | Filters visible, trending topics loaded | 3/5 Curious |
| 0:15 | Searched "transformers time series weather prediction" | Found 6 AI-matched + 30 keyword results in ~8s | 5/5 Excited |
| 0:35 | Opened Research Advisor | Clean interface, suggested starter queries | 4/5 Interested |
| 0:50 | Asked cross-domain question about NLP‚Üíclimate transfer | Got 5 climate-specific papers, synthesis unavailable | 5/5 Delighted |
| 1:20 | Expanded paper detail (PFformer) | Full abstract visible, "Generate Code" link | 4/5 Pleased |
| 1:35 | Final state assessment | Stayed on explore page with search results | 4/5 Satisfied |

---

## Pain Points Assessment

### Did AI Paper Atlas solve my interdisciplinary challenges?

#### ‚úÖ **SOLVED: Cross-Domain Discovery**
- **Problem**: Techniques developed for NLP/vision published in venues I don't follow
- **Solution**: Research Advisor surfaced papers like "Data-driven Seasonal Climate Predictions via Variational Inference and Transformers" - directly applicable to my work
- **Evidence**: Got 5 climate-specific transformer papers from semantic search, vs. 0 expected from traditional keyword search
- **Impact**: High - this is my #1 pain point

#### ‚úÖ **PARTIALLY SOLVED: Terminology Gap**
- **Problem**: ML papers use different terminology than climate science
- **What Worked**: Semantic search understood "weather prediction" = "nowcasting", "climate model time series" = "spatiotemporal forecasting"
- **What Didn't**: Papers still use ML jargon without explanation (e.g., "position-free transformer," "Enhanced Feature-based Embedding")
- **Missing**: Glossary or tooltip system explaining ML terms for domain scientists
- **Impact**: Medium - I can read the papers, but slowly

#### ‚ùå **NOT TESTED: Adaptation Complexity**
- **Problem**: Hard to know if NLP/vision methods will transfer to physical science data
- **Why Not Tested**: Didn't explore far enough to see transfer analysis
- **Suggestion**: Papers could have "Domain Applicability" tags (e.g., "Time Series," "Physical Systems," "Spatial Data")

#### ‚ùå **NOT TESTED: Justification to Peers**
- **Problem**: Need to justify ML approaches to skeptical climate scientists
- **Why Not Tested**: Didn't look for interpretability/explainability papers specifically
- **Suggestion**: Filter for "Interpretable ML" or "Explainable AI" methods

#### ‚ö†Ô∏è **UNCLEAR: Finding Foundational Papers**
- **Problem**: Haven't read "foundational" ML papers, missing context
- **Observation**: Saw "Seminal Papers" filter (Top 1% cited) - this could help
- **Not Tested**: Didn't try building a learning path for transformers basics

---

## Cross-Domain Discovery Assessment

### Semantic Search Quality: **Excellent (5/5)**

The AI-powered search **understood my intent despite domain-specific language**:

**Query**: "transformers time series weather prediction"

**Top Results** (all highly relevant):
1. ‚úÖ Solar Forecasting with Causality (renewable energy - adjacent domain)
2. ‚úÖ PFformer for Extreme-Adaptive MTS Forecasting (weather, energy, finance)
3. ‚úÖ UNet with Axial Transformer for Precipitation Nowcasting (direct hit!)
4. ‚úÖ Lightweight Multivariate Time Series (mentions weather explicitly)

**Contrast with typical keyword search**: On Google Scholar, I'd get generic "transformer" papers (NLP models) mixed with irrelevant results. Here, **every top-6 paper applies to physical/scientific domains**.

### Research Advisor Cross-Domain Performance: **Outstanding (5/5)**

**My Question**: "I need to apply transformers to climate model time series. What techniques from NLP might transfer to physical science data?"

**Advisor Response**:
- **Understood cross-domain intent** (NLP ‚Üí climate transfer)
- **Surfaced climate-specific papers**:
  - "Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales"
  - "Data-driven Seasonal Climate Predictions via Variational Inference and Transformers"
- **Note**: Contextual synthesis was unavailable, but paper selection was highly relevant

**This is exactly what I need** - not generic ML papers, but work that already bridges the gap between ML techniques and climate applications.

---

## Accessibility for Non-ML Experts

### Jargon Density: **High (2/5 accessibility)**

**Examples from PFformer abstract** (unexplained terms):
- "Transformer-based models"
- "singular token embedding"
- "inter-variable relationships"
- "Enhanced Feature-based Embedding (EFE)"
- "Auto-Encoder-based Embedding (AEE)"
- "positional encoding"

**For a climate scientist**:
- I understand "multivariate time series" ‚úÖ
- I understand "forecasting" ‚úÖ
- "Transformer" is vaguely familiar (heard of it) ‚ö†Ô∏è
- "Token embedding" - no idea ‚ùå
- "Auto-encoder" - no idea ‚ùå
- "Positional encoding" - no idea ‚ùå

### What Would Help:

1. **Inline glossary tooltips**: Hover over "transformer" ‚Üí "Architecture that uses attention mechanisms to process sequential data"
2. **"Explain for domain scientists" button**: Simplify abstract for non-ML audience
3. **Difficulty tags that actually mean something**:
   - Current: "Advanced" (unclear)
   - Better: "Requires ML background" vs. "Application-focused (minimal ML knowledge needed)"

### Code Availability: **Not Assessed**

- Saw "Generate Code" link on expanded paper ‚úÖ
- Saw "Has Code" filter in sidebar ‚úÖ
- **Did not test**: Whether code examples are adapted for scientific data (vs. NLP datasets)
- **Critical for me**: Need code that works with NetCDF files, climate model output, not text data

---

## Transfer Potential Evaluation

### How well does it surface applicable techniques?

**Strong**: Semantic search filtered out irrelevant NLP-only work
- No papers about text generation, chatbots, or language models
- All top results mention physical domains (weather, energy, finance)

**Weakness**: No explicit "transferability score"
- Would love to see: "Transferability: High - designed for physical time series data"
- vs. "Transferability: Low - assumes NLP-specific data structure"

**Missing Feature**: "Similar Domains" tag
- Paper could show: "Also applied to: oceanography, renewable energy forecasting, hydrology"
- This would help me identify peer disciplines facing similar challenges

---

## Visual Observations

### Layout & Information Density

**Positive**:
- Clean, professional interface - feels like a research tool, not a consumer app
- Search results prioritize relevance (AI-matched first, keyword second)
- TL;DR summaries helpful for quick scanning
- Filters visible but not overwhelming

**Negative**:
- Initial load had long skeleton screen phase (3-5s felt slow)
- Research Advisor took 15+ seconds to respond (timed out waiting for synthesis)
- No visual distinction between "I understand this paper" vs. "this is above my level"

### Screenshots Captured

1. **01-landing-first-impression.png**: Skeleton loading state
2. **02-page-loaded.png**: Still loading (longer than expected)
3. **03-explore-ready.png**: Fully loaded with trending topics
4. **04-discovery-nav.png**: Discovery section with multiple tabs
5. **05-search-query-typed.png**: Semantic search in progress
6. **06-search-results.png**: 6 relevant results found
7. **07-advisor-opened.png**: Research Advisor panel
8. **08-advisor-query-typed.png**: Cross-domain question entered
9. **09-advisor-response.png**: Climate-specific papers returned
10. **10-paper-expanded.png**: Full abstract + Generate Code link
11-15. **Additional states**: Filter interactions, final views

---

## Delights

### üéâ **Cross-Domain Paper Discovery**
- **What**: Research Advisor understood "NLP techniques transferring to climate data" and found relevant papers
- **Why It Matters**: This is impossible with keyword search. I'd never find "Data-driven Seasonal Climate Predictions via Variational Inference and Transformers" on my own.
- **Emotion**: **5/5 - Genuine delight**

### üéâ **Semantic Search Worked!**
- **What**: Searched "transformers time series weather prediction" ‚Üí got weather papers, not NLP papers
- **Why It Matters**: Google Scholar would drown me in irrelevant "transformer model" (NLP) results
- **Emotion**: **5/5 - Exactly what I needed**

### üòä **Generate Code Link**
- **What**: Saw "Generate Code" button on paper detail
- **Why It Matters**: I learn by adapting code, not reading math
- **Caveat**: Didn't test if code is adapted for climate data
- **Emotion**: **4/5 - Promising but untested**

---

## Frustrations

### üò§ **ML Jargon Everywhere**
- **What**: Papers assume I know what "attention mechanisms," "positional encoding," "token embeddings" mean
- **Impact**: I can use the tool to find papers, but reading them is still intimidating
- **Emotion**: **2/5 - Feels like I'm not the target audience**
- **Fix**: Add "Explain for domain scientists" mode or glossary tooltips

### üòï **Research Advisor Timeout**
- **What**: Advisor took 15+ seconds, then said "Contextual synthesis temporarily unavailable"
- **Impact**: Got paper list (good) but no synthesized answer (disappointing)
- **Emotion**: **3/5 - Functional but not delightful**
- **Fix**: Show progress indicator, or offer partial results faster

### üòê **No Domain Tags**
- **What**: Papers show "CS.LG" or "CS.AI" but not "Climate," "Weather," "Geoscience"
- **Impact**: Have to read abstracts to confirm applicability
- **Emotion**: **3/5 - Minor friction**
- **Fix**: Add domain application tags (Climate, Energy, Oceanography, etc.)

---

## Performance Metrics

| Metric | Value | Assessment |
|--------|-------|------------|
| Initial page load | ~3-5s | Acceptable (felt slow due to skeletons) |
| Search response time | ~8s | Good (complex semantic search) |
| Research Advisor response | 15s+ (timeout) | Poor (needs optimization or progress bar) |
| Results relevance | 6/6 top papers relevant | Excellent |
| Cross-domain accuracy | 100% (all papers apply to physical science) | Outstanding |

---

## Priority Improvements

Ranked by **Impact √ó Feasibility** for interdisciplinary researchers:

### üî¥ **P0: Critical**

1. **Add Glossary/Tooltip System** (High Impact, Med Effort)
   - Hover over ML terms ‚Üí plain language explanation
   - Example: "Transformer" ‚Üí "Neural network that uses attention to process sequences"
   - **Why**: Makes tool accessible to domain scientists, not just ML experts

2. **Optimize Research Advisor Performance** (High Impact, High Effort)
   - 15s timeout is too slow for interactive use
   - Show progress bar or partial results
   - **Why**: Advisor is killer feature for cross-domain search

### üü° **P1: High Value**

3. **Add Domain Application Tags** (High Impact, Low Effort)
   - Tag papers with: Climate, Weather, Energy, Oceanography, Hydrology, etc.
   - Filter by domain, not just CS category
   - **Why**: Helps me find peers working on similar problems

4. **"Explain for Domain Scientists" Mode** (Med Impact, Med Effort)
   - Simplify abstract using LLM
   - Remove ML jargon, emphasize application
   - **Why**: Lowers barrier to entry for non-ML researchers

### üü¢ **P2: Nice to Have**

5. **Transferability Score** (Med Impact, High Effort)
   - Rate how well a technique transfers to new domains
   - Based on: data type compatibility, domain diversity of citations
   - **Why**: Helps assess if a paper is worth deep reading

6. **Learning Path for Foundational Concepts** (Med Impact, Med Effort)
   - "New to Transformers? Start here: [3 foundational papers]"
   - Leverage "Seminal Papers" filter + difficulty ranking
   - **Why**: Fills gaps in ML background

---

## Final Verdict

### Would I use this tool?

**Yes - with enthusiasm and a learning curve.**

### Would I recommend to climate science colleagues?

**Yes, but with caveats**:
- ‚úÖ **Recommend to**: Colleagues with some ML background, comfortable reading papers
- ‚ö†Ô∏è **Recommend with guidance to**: Early-career researchers, need to explain ML terms first
- ‚ùå **Not yet for**: Pure climate scientists with zero ML exposure (too much jargon)

### What would make it indispensable?

1. **Glossary system** - Let me learn ML vocabulary in context
2. **Domain tags** - Help me find my research community (climate ML, not just general ML)
3. **Code adapted for scientific data** - NetCDF/HDF5 support, not just CSV/text

### My honest take as a domain scientist:

This tool **solves a real problem I face daily** - finding ML techniques that apply to climate data. The semantic search and Research Advisor are genuinely better than Google Scholar for cross-domain discovery. However, it still feels **built for ML researchers first, domain scientists second**. With better accessibility features (glossary, simplified abstracts), this could be **the tool that helps climate scientists adopt ML**, not just find papers about it.

**Final Score: 4/5** - Excellent core functionality, needs accessibility layer for non-ML experts.

---

## Screenshot Index

| # | Filename | Description |
|---|----------|-------------|
| 01 | `01-landing-first-impression.png` | Initial page load with skeleton screens |
| 02 | `02-page-loaded.png` | Still loading state |
| 03 | `03-explore-ready.png` | Fully loaded explore page with trending topics |
| 04 | `04-discovery-nav.png` | Discovery section navigation tabs |
| 05 | `05-search-query-typed.png` | Search query entered, semantic search starting |
| 06 | `06-search-results.png` | 6 AI-matched + 30 keyword results displayed |
| 07 | `07-advisor-opened.png` | Research Advisor panel opened with starter queries |
| 08 | `08-advisor-query-typed.png` | Cross-domain question typed in Advisor |
| 09 | `09-advisor-response.png` | Climate-specific papers returned by Advisor |
| 10 | `10-paper-expanded.png` | Full abstract view with Generate Code link |
| 11 | `11-paper-detail.png` | Paper detail with tabs (Summary, Related, Benchmarks) |
| 12 | `12-code-filter.png` | Same view (attempted filter interaction) |
| 13 | `13-discovery-page.png` | Same view (attempted navigation) |
| 14 | `14-discovery-tabs.png` | Same paper expanded view |
| 15 | `15-final-state.png` | Final state - paper list with one expanded |

**Total Screenshots: 15**

---

## Appendix: Cross-Domain Query Examples

### Queries that would work well:
- "machine learning for oceanography"
- "neural networks predicting extreme weather"
- "transformers for satellite imagery time series"
- "physics-informed neural networks climate"

### Queries that might struggle:
- "ML for CMIP6 models" (too specific/jargon-heavy)
- "AI for climate change" (too broad, not technical)
- "attention mechanisms" (too ML-focused, no domain context)

---

**Assessment completed by**: Dr. Emily Zhang (simulated)
**Key Insight**: AI Paper Atlas is a powerful cross-domain discovery tool that needs an accessibility layer (glossary, domain tags, simplified abstracts) to fully serve interdisciplinary researchers teaching themselves ML.
